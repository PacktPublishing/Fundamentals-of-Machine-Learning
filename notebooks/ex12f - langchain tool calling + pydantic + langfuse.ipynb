{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2/stmQFKlmS6mRIdmCvLi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzEeBdFp8abQ","executionInfo":{"status":"ok","timestamp":1751141629338,"user_tz":240,"elapsed":14674,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"9ad21868-ee3e-466a-c5a2-795fe17d10c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n","Collecting dateparser\n","  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n","Collecting langfuse\n","  Downloading langfuse-3.0.7-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.2)\n","Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n","Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n","Collecting backoff>=1.10.0 (from langfuse)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Collecting opentelemetry-api<2.0.0,>=1.33.1 (from langfuse)\n","  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-exporter-otlp<2.0.0,>=1.33.1 (from langfuse)\n","  Downloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from langfuse)\n","  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: packaging<25.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langfuse) (24.2)\n","Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.11/dist-packages (from langfuse) (1.17.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse) (8.7.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc==1.34.1 (from opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.34.1 (from opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.70.0)\n","Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (1.73.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n","Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.34.1->opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp<2.0.0,>=1.33.1->langfuse) (5.29.5)\n","Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse)\n","  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse) (3.23.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n","Downloading langchain_openai-0.3.27-py3-none-any.whl (70 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langfuse-3.0.7-py3-none-any.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.3/294.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl (7.0 kB)\n","Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl (17 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: opentelemetry-proto, backoff, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, dateparser, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, opentelemetry-exporter-otlp, langfuse\n","Successfully installed backoff-2.2.1 dateparser-1.2.2 langchain-openai-0.3.27 langfuse-3.0.7 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-exporter-otlp-proto-http-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1\n"]}],"source":["pip install langchain langchain-openai openai dateparser langfuse"]},{"cell_type":"code","source":["from google.colab import userdata\n","OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","\n","import os\n","\n","# Replace with your actual key or keep as-is if it's already in a variable\n","os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"],"metadata":{"id":"Ymm_W7InLG66","executionInfo":{"status":"ok","timestamp":1751141631301,"user_tz":240,"elapsed":1960,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","from typing import Callable, Dict, List, Tuple, Optional\n","\n","from pydantic import BaseModel\n","from langchain_core.tools import Tool\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain.agents import create_openai_functions_agent, AgentExecutor\n","\n","from langfuse import Langfuse, get_client\n","from langfuse.langchain import CallbackHandler"],"metadata":{"id":"A8XphW7dLJpu","executionInfo":{"status":"ok","timestamp":1751141761061,"user_tz":240,"elapsed":11002,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Initialize Langfuse tracing client at startup\n","Langfuse(\n","    public_key=os.environ.get(\"LANGFUSE_PUBLIC_KEY\", \"pk-lf-a5edd784-d1c7-4c6c-a1d3-6c8288285b65\"),\n","    secret_key=os.environ.get(\"LANGFUSE_SECRET_KEY\", \"sk-lf-79ef80bf-d991-4e2e-9f58-9b468aaccccd\"),\n","    host=os.environ.get(\"LANGFUSE_HOST\", \"https://us.cloud.langfuse.com\"),\n",")\n","langfuse = get_client()\n","langfuse_handler = CallbackHandler()"],"metadata":{"id":"BYzcY8NiLpSs","executionInfo":{"status":"ok","timestamp":1751141779237,"user_tz":240,"elapsed":1178,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Global list to track tool usage during each interaction\n","TOOL_USAGE_LOG: List[str] = []\n","\n","class ChatbotResponse(BaseModel):\n","    \"\"\"\n","    Structured output of the chatbot for logging or downstream usage.\n","    \"\"\"\n","    thought: str\n","    message: str\n","    tools: List[str]\n","\n","\n","def tracked_tool(name: str, func: Callable[[str], str]) -> Callable[[str], str]:\n","    \"\"\"\n","    Wraps a tool function to log its name when called.\n","\n","    Args:\n","        name: Tool identifier.\n","        func: Underlying processing function.\n","\n","    Returns:\n","        Wrapper that logs usage and invokes the tool.\n","    \"\"\"\n","    def wrapper(input_text: str) -> str:\n","        TOOL_USAGE_LOG.append(name)\n","        return func(input_text)\n","    return wrapper\n","\n","\n","def simple_calculator(query: str) -> str:\n","    \"\"\"\n","    Evaluates a math expression.\n","\n","    Args:\n","        query: Expression string.\n","\n","    Returns:\n","        Computed result or error message.\n","    \"\"\"\n","    try:\n","        result: float = eval(query, {\"__builtins__\": {}})\n","        return str(result)\n","    except Exception as err:\n","        return f\"Error in calculation: {err}\"\n","\n","\n","def get_calculator_tool() -> Tool:\n","    \"\"\"\n","    Builds calculator tool with logging wrapper.\n","\n","    Returns:\n","        Tool instance.\n","    \"\"\"\n","    return Tool(\n","        name=\"Calculator\",\n","        description=\"Evaluates basic math expressions.\",\n","        func=tracked_tool(\"Calculator\", simple_calculator),\n","    )\n","\n","\n","def get_llm() -> ChatOpenAI:\n","    \"\"\"\n","    Initializes the OpenAI chat model.\n","\n","    Returns:\n","        ChatOpenAI instance.\n","\n","    Raises:\n","        ValueError: If the API key is not set.\n","    \"\"\"\n","    api_key: Optional[str] = os.environ.get(\"OPENAI_API_KEY\")\n","    if not api_key:\n","        raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n","    return ChatOpenAI(model=\"gpt-4\", temperature=0.0, openai_api_key=api_key)\n","\n","\n","def get_prompt() -> ChatPromptTemplate:\n","    \"\"\"\n","    Constructs and returns the prompt structure for the agent.\n","    \"\"\"\n","    return ChatPromptTemplate.from_messages([\n","        (\"system\", \"You are a helpful assistant that can use tools.\"),\n","        (\"user\", \"{input}\"),\n","        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n","    ])\n","\n","\n","def get_agent_chain_and_tools() -> Tuple[AgentExecutor, List[Tool]]:\n","    \"\"\"\n","    Constructs the AgentExecutor with Langfuse callback for tracing.\n","\n","    Returns:\n","        Tuple of AgentExecutor and list of tool instances.\n","    \"\"\"\n","    llm = get_llm()\n","    tools = [get_calculator_tool(),]\n","    prompt = get_prompt()\n","\n","    # Create a tool-enabled agent\n","    agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)\n","\n","    # Attach Langfuse tracing callback\n","    agent_executor = AgentExecutor(\n","        agent=agent,\n","        tools=tools,\n","        verbose=True,\n","        callbacks=[langfuse_handler],\n","    )\n","\n","    return agent_executor, tools\n","\n","\n","def run_chat_loop(agent_chain: AgentExecutor, tools: List[Tool]) -> None:\n","    \"\"\"\n","    Runs the interactive CLI loop, tracing each message.\n","\n","    Args:\n","        agent_chain: Configured AgentExecutor with tracing.\n","        tools: Available tool instances.\n","    \"\"\"\n","    print(\"Chatbot is ready. Type 'exit' to quit.\")\n","    while True:\n","        user_input: str = input(\"User: \")\n","        if user_input.lower() in {\"exit\", \"quit\"}:\n","            print(\"Exiting chatbot.\")\n","            break\n","\n","        try:\n","            TOOL_USAGE_LOG.clear()\n","            raw_response: Dict[str, str] = agent_chain.invoke({\"input\": user_input})\n","            used_tools = TOOL_USAGE_LOG.copy()\n","\n","            thought = (\n","                f\"Processed using tool(s): {', '.join(used_tools)}\"\n","                if used_tools else \"No tools used.\"\n","            )\n","\n","            structured = ChatbotResponse(\n","                thought=thought,\n","                message=raw_response.get(\"output\", \"[No output]\"),\n","                tools=used_tools,\n","            )\n","            print(\"Structured Response:\", structured.model_dump_json(indent=2))\n","        except Exception as err:\n","            print(\"Error during chat:\", err)\n","\n","    # Flush trace data to Langfuse so it appears in the UI\n","    langfuse.flush()"],"metadata":{"id":"0HOdZjs_LwIP","executionInfo":{"status":"ok","timestamp":1751141994228,"user_tz":240,"elapsed":15,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["agent_chain, tool_list = get_agent_chain_and_tools()\n","run_chat_loop(agent_chain, tool_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyKJMVQuMk5M","executionInfo":{"status":"ok","timestamp":1751142129167,"user_tz":240,"elapsed":115069,"user":{"displayName":"Yiqiao Yin","userId":"16271867367914268422"}},"outputId":"b9a576ce-f947-4419-bbfa-c771306c141c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Chatbot is ready. Type 'exit' to quit.\n","User: tell me a joke\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3mSure, here's a classic one for you:\n","\n","Why don't scientists trust atoms?\n","\n","Because they make up everything!\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Structured Response: {\n","  \"thought\": \"No tools used.\",\n","  \"message\": \"Sure, here's a classic one for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\",\n","  \"tools\": []\n","}\n","User: what is 3+5-19/23\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `Calculator` with `3+5-19/23`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m7.173913043478261\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n","WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3mThe result of the expression 3+5-19/23 is approximately 7.17.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Structured Response: {\n","  \"thought\": \"Processed using tool(s): Calculator\",\n","  \"message\": \"The result of the expression 3+5-19/23 is approximately 7.17.\",\n","  \"tools\": [\n","    \"Calculator\"\n","  ]\n","}\n","User: what is 4-5*(9-1/18)\n","\n","\n","\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\n","Invoking: `Calculator` with `4-5*(9-1/18)`\n","\n","\n","\u001b[0m\u001b[36;1m\u001b[1;3m-40.72222222222222\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n","WARNING:opentelemetry.sdk.trace:Calling end() on an ended span.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3mThe result of the expression 4-5*(9-1/18) is approximately -40.72.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","Structured Response: {\n","  \"thought\": \"Processed using tool(s): Calculator\",\n","  \"message\": \"The result of the expression 4-5*(9-1/18) is approximately -40.72.\",\n","  \"tools\": [\n","    \"Calculator\"\n","  ]\n","}\n","User: quit\n","Exiting chatbot.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cv1pTZ4MMpwY"},"execution_count":null,"outputs":[]}]}